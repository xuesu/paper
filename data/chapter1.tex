\chapter{绪论}

\section{研究背景及意义}
情感分析，又称为观念挖掘，指使用计算语言学的知识，对文本进行分析与自然语言处理，从而识别并抽取出语言材料中的主观信息的过程\cite{Tejwani2014}。情感分析能够自动挖掘文本信息隐含的情况，态度，意见等，在舆情分析，自动决策支持，广告推荐等方面都具有很大价值\cite{Zhang2016}。目前情感分析的主要研究领域有情感分类，情感强度预测以及观点挖掘\cite{Tejwani2014}。其中按照处理文本的粒度，情感分类任务常被划分为三种等级：一. 篇章级，也即长文本，二. 句子级，也即短文本，三. 实体或特征级，四. 单词或短语级。\cite{Zhang2016} \cite{Liu2016} \cite{Zhao2010}。实体或特征级情感分析任务具体研究语料中某个方面或者某个对象的情感，而不输出对文本整体的情感分析。本文主要关注语句级和实体级的情感分类任务，即抽取语句整体情感极性或句中实体的情感极性，判断其是否为正向，负向，中性或者矛盾。

目前国内外的研究学者和开发者主要通过三大类方法解决文本情感分类，即基于知识的方法，基于统计的方法或聚合的方法\cite{Zong2013}。基于知识的代表性算法为基于情感词典的方法，例如Kim S M等\cite{Kim2006}使用情感词典采用语义角色标注的方式衡量文本情感极性，Tong R M \cite{Tong2001}则根据不同领域使用不同的人工词典，但基于知识的方法往往实现复杂，且鲁棒性一般较差，仅能在小规模的数据上取得一定成果，很难进行进一步的优化\cite{Zong2013}。
基于统计的方法则主要为机器学习算法。由于情感分类本质上是文本分类问题，故典型的模式分类算法往往可以应用于情感分类领域，如Pang等\cite{bopang2002}采用有监督的学习方法，包括朴素贝叶斯NB，最大熵ME和支持向量机SVM，获得了比人工标注的语料库方法更好的结果。

但传统的机器学习方法如NB，ME，SVM等基本可以归类为浅层学习，这些方法难以表达复杂非线性函数，同时过度依赖于研究人员依靠经验选择的高级特征。而随着神经网络这一技术的流行，由于其可以通过神经网络中多个非线性映射的隐藏层逐层计算逼近复杂函数，同时可以自动从低级特征中学到如何表达高级特征的特性，越来越多的研究者转向使用深度神经网络进行自然语言处理，与此同时，情感分类中仍存在许多问题没有得到很好的解决，因此，本文以提高文本情感分类系统性能为目标，重点研究如何使用深度学习对文本进行情感分析。本文实现的模型具有较好的迁移性，可以运用于评论分析，舆情分析等多个领域，因此，该课题具有较高的研究价值。
\section{主要挑战}
情感分类是一个非常热门的研究领域，自提出以来经过了井喷式的发展\cite{Liu2016}。但实际分析中，待分析文本往往词汇丰富，又具有语义多样性，而且往往具有复杂的语法结构及不规范的语用现象如冗余，重复等\cite{Zong2013}，并且还受到以下不可避免的问题约束，故该领域依然存在巨大挑战。
\subsection{客观语句}
定义客观语句为描述世界的客观现实的语句，而主观语句为表达个人感受，观点或信念的语句\cite{Liu2016}，则在通常情况下主观语句是情感分类的主要研究对象，但实际上，主观语句可能并不带有情感信息，如“我认为蜜蜂蜇人更疼。”，而客观语句所描述的现实可能带有说话人的情感，比如“浴缸有条裂缝。”该句可能带有买家对浴缸这种商品的负向情感，故简单以主观语句作为分析对象是不行的。实际上，本文测试所用到的NLPCC 2014(The 3rd CCF Conference on Natural Language Processing \& Chinese Computing)的SCDL(Sentiment Classification with Deep Learning) 数据集，和展示用到的携程等数据集都含有大量标注为带有情感极性的客观语句。
\subsection{歧义}
歧义消解一直是自然语言处理面临的核心问题，对于“你今天怎么这么早？”这句话，根据不同的上下文语境，可能有不同的理解。如：“你今天怎么这么早？怪不得教室被打扫地这么干净。”与“你今天怎么这么早？我还没做好派对的准备。”在不同的上下文语境中，同一句话表达了不同的情感。歧义消解不仅需要考虑上下文，还往往要求系统具备某一领域的常识。在上面例子中，“没有做好派对的准备”往往代表主人还不欢迎客人的到来，也即带有负向情感。
\subsection{实体}
在系统实际处理的文本中，说话人，即输入文本的作者常与不同实体如地点，机构，人名产生联系。例如“我买了美美的家具”，该句中的“美美”可能为正向形容词，也可能为“美美家居”。当将实体词误判为形容词或相反后，语句的语法结构会被破坏，更可能引发歧义，为情感分类系统及其它自然语言处理系统带来困难。
\subsection{标注集}
由于自然语言结构复杂，故采用机器学习训练自然语言时，往往需要大量标注集作为训练语料。若采用人工方式进行标注需要大量的人力投入，实际上标注集往往通过爬取评论等带有评分的语料文本自动获取标签。但本文通过研究发现，由于不同用户的打分标准不同，采用评分方式获取标签准确度不能达到百分之百，也即训练集和测试集中往往有错误。
以下是NLPCC 2014 SCDL数据集中的一条数据，在训练集中，该句被标注为带有正面情感倾向。：
 
    <review id="225">
        不怎么怎么搞的，一带上去皮肤就过敏
    </review>
   
实际上，即使人工标注数据，也往往存在标注规范不一致的情况。
例如对于“还可以吧”这句评论，说话者既有可能带有负向情感，当说话者对比的目标都很差时，也有可能带有正向情感。
\section{研究现状}
目前情感分析领域主要采用基于知识的方法和基于统计的方法，而后者则可以分为传统浅层机器学习方法和深度学习方法，本章将分别就三种方法在句子级上的研究进展加以介绍。
\subsection{基于知识的情感分类方法}
基于知识的情感分类方法往往利用可靠的情感词典，通过分析语句中较为常见的语法关系和语法现象对语句进行情感分类。

典型的构建情感词典的方式有人工构建和自动拓展种子词的方法，而后者又分为基于知识库的方法，基于语料库的方法和二者相结合的方法\cite{Wang2016}。

基于知识库的方法一般需要有完备的语义知识库（如Wordnet）和人工事先标注正确情感的种子词，研究者依据种子词的情感极性，通过挖掘语义知识库中词语之间的关系推测未标注词的情感极性从而建立情感词典，如Hu\cite{huliu2004a}等通过同义词与反义词关系拓展情感形容词词典，最后人工筛选错误分类的词汇。由于知识库结构复杂，词汇经过若干次迭代后，可能会迭代为相反的情感极性，Kamps等\cite{Kamps04a}使用未标注词迭代为正向词和迭代为负向词所需次数之差来估计未标注词的情感极性。

由于情感词汇可能在不同的领域内表现不同的情感，因此基于知识库的方法不适用于该情景，只能构建通用情感词典，而基于语料库的方法则可以根据某领域内的大量语料推测情感词极性，能较好地解决该问题。Kanayama等\cite{Kanayama2006}认为短句中连续的情感词极性相近，遇到转折词如but后，极性则会反转。Turney\cite{turneylittman2003}使用词语与正面或负面种子词的点互信息(Pointwise mutual information, PMI)判断词语极性。二者结合的算法则能同时利用词义关系和语料中的共现信息，位置信息等关系，如Esuli\cite{Esuli2007}等使用PageRank算法，通过同义词间关系构建情感词典。深度学习在构建情感词典方面的应用也逐渐增长，如Tang\cite{Tang2014b}等改进Word2Vec模型，通过在训练时添加中心词极性和所在句子训练带有情感的短语向量(Sentiment-Specific Phrase Embedding)。

典型的使用情感词典进行情感分类的算法可能是简单将情感词加和，但更多需要结合语法特征，如Choi等\cite{Choi2008}定义一系列规则，例如对于二元词组，若第一个词为否定词，则其情感极性为第二个词的相反极性，若二者极性相同，则为该极性，否则，使用训练语料中词语的主要极性，以此计算语句极性。Moilanen等\cite{Moilanen2007}使用语法树计算语句情感极性，以此处理情感传播，极性冲突和极性转换等问题。Liang等\cite{Liang2013}则通过依赖关系进行判断。

本文实现的基于知识的情感分类模型主要基于Stanford语法树。Baker等\cite{Baker79}于1979年提出使用隐马尔科夫模型训练基于概率上下文无关文法(PCFG)的语法树。但由于PCFG将短语中的每个部分等价处理，可能导致语法二义性，Ford等\cite{Ford1982}提出了词汇化的PCFG（lexicalized-PCFG），该文法为每个规则添加规则的首要词HEAD，以获得语法树的更准确表示。Klein等\cite{Klein2003}采用标记父节点和使用马尔科夫模型决定候选规则等方式优化了未词汇化的PCFG，该方法成为了Stanford语法树的理论基础。
\subsection{基于传统机器学习的情感分类方法}
有监督算法中，Pang等\cite{bopang2002}采用有监督的学习方法，包括朴素贝叶斯NB，最大熵ME和支持向量机SVM，获得了比人工标注的语料库方法更好的结果。2004年,Pang等\cite{Pang2004}使用图最小割算法进行情感分析。Nakagawa等\cite{Nakagawa2010}使用子依存树的极性作为输入特征之一训练带有隐藏变量的CRF模型来处理情感分类问题。Mullen等\cite{Mullen2004}使用包括PMI，Osgood语法差异\cite{Osgood1957}，主题相近程度和其它一些语法特征作为SVM输入。Kennedy等\cite{Kennedy2006}将转折词等也作为输入特征。Abbasi等\cite{Abbasi2008}提出了熵权重一般算法(Entropy Weighted Genetic Algorithm, EWGA)用以生成SVM的输入特征。

无监督方法中，Choi等\cite{Do2015}基于形容词在不同主题中情感极性可能不同这一特点，假设在同一主题中形容词的极性相同，提出了bootstrapping算法，该算法首先产生种子情感词，然后通过实体和情感词间的依赖关系识别训练样本中的主题将语句表达为特征向量，拓展种子词，最后通过Kmeans聚类获取语句情感分类。Lin等\cite{Lin2010}基于LDA模型实现了LSM(Latent Sentiment Model)、JST(Joint Sentiment-Topic)、Reverse-JST(Reverse-Joint Sentiment-Topic)三种无监督的情感分析模型。

半监督算法中，Davidov等\cite{Davidov2010}通过高频词和内容词等从训练语料中抽取语句模式，删除商品描述中存在的模式，将语句和模式的匹配程度作为半监督学习器的输入特征。Riloff等\cite{Riloff2003}使用Meta-Bootstrapping和Basilisk算法进行主观名词的识别并以此获取语句主客观信息。Su等\cite{Su2009}提出了半监督最小割算法。
\subsection{基于深度学习的情感分类模型}
深度学习最初使用one-hot编码表示向量，则输入特征空间复杂度至少为语句长度乘以词汇表大小，这很可能会引发维度灾难问题。Bengio等\cite{Bengio2003}根据单词上下文往往与单词自身语义有关的性质，通过训练带有一层投影层的神经网络，训练目标为用单词的上文预测单词本身来获取单词的向量表示。Mikolov等\cite{mikolov2013} \cite{mikolov2013b}改进了Bengio的算法，取消了投影层，提出了Continuous Skip-Gram模型和 Continuous Bag-of-Words模型，并使用层次softmax或负采样方法训练模型。Collobert等\cite{collobert2011}提出了C\&W模型，该模型主要分为输入层，查表层，卷积层，池化层，线性层等，被设计可应用于多种自然语言处理任务，包括对单词和语句的处理及分类，语法角色标注，词性标注等。C\&W模型也可以运用于无监督或有监督生成词向量。Tang等\cite{Tang2014c}在C\&W基础上，加入语句情感极性训练以此得到带有情感的词向量。

在使用深度学习进行情感分析方面，Socher\cite{Socher2011}使用无监督递归自编码器(RAE)预测语句语法结构与每个节点的向量表示，加入softmax层用以分类文本。但Socher认为基于单个单词的RAE无法识别短语的位置信息，而计算短语的组合函数依赖于短语中的每个单词，因此Socher在2012年\cite{Socher2012}提出了Matrix-Vector RNN模型以改进该模型。MV-RNN模型在Socher RAE模型的基础上，为每个单词添加$d \times d$了矩阵（此处d为单词表长度），用于根据上下文计算短语特征。但也正是因为该模型为每个单词添加的参数矩阵导致算法总体时空复杂度过高，需要训练的参数也过多，Socher在2013年对该模型提出了改进\cite{Socher2013}，对所有节点使用一个统一的基于张量的组合函数，即为RNTN(Recursive Nerual Tensor Network)模型。Bespalov等\cite{Bespalov2011}使用滑动窗口建立n元短语表示模型并以此进行情感分析。Cao\cite{CaoXC15}结合CNN模型与SVM模型，将CNN输出作为SVM的输入特征进行训练，取得了不错的成果。
\section{论文主要研究内容及组织结构}
本文探索基于深度学习的文本情感分析方法，并针对文本情感分析的方法对模型进行改进和调整以适应特定任务。

本文主要工作内容分为以下两个部分：

1. 研究语句级的情感分析模型。本文主要实现了三个模型，基于Stanford Parser语法树的纯知识模型，基于长短时记忆循环神经网络(LSTM)的神经网络模型和基于卷积神经网络(CNN)的神经网络模型。在三个模型中CNN模型和LSTM模型在简单的评论数据集上都表现良好，但在NLPCC2014的SCDL模型上LSTM模型表现更好，在中英双语上都接近比赛评测第一名的结果，结果说明相较于CNN，RNN更适应于处理序列文本。同时，经过重复实验发现，相较于对整句抽取，对语句局部抽取特征后进行最大池化往往准确度更高，泛化能力更强。

2. 研究实体级的情感分析模型。本文通过中/英文实体识别工具为每个单词标明对应实体属性，将实体情感分类任务转化为序列到序列(seq2seq)的翻译任务。本文基于google的seq2seq模型\cite{seq2seq2014}和Attention模型\cite{attention2014}进行了改进，实现了基于LSTM和AM模型的RNN实体情感分析模型。同时，本文实现了基于CNN的实体情感分析模型作为对比。

本文组织架构如下：
\begin{itemize}
\item 第一章\ 绪论：介绍了本文的研究背景和意义，文本情感分类所面临的挑战，以及相关研究工作。同时介绍了本文的主要内容。
\item 第二章\ 数据获取与预处理：分别介绍了中英文下情感处理的一般预处理流程和流程中用到的工具。介绍了测试集及对应获取方法，以及基于stanford\ parser语法树的知识模型所用到的情感词典。
\item 第三章\ 语句级情感分析：分别介绍了基于Stanford语法树的纯知识模型，基于深度学习的CNN模型和使用了LSTM的RNN模型。介绍了模型的一般流程和相关知识。本章第二部分使用不同数据集对三种模型进行性能分析。最后，本章对深度学习模型参数进行调整分析，同时提出了若干适应于文本情感分析的深度神经网络的技巧。
\item 第四章\ 实体级情感分析：介绍了实体级情感分析的一般流程，然后分别介绍了CNN模型及RNN模型和相关知识，最后使用数据集对模型进行评测，同时对参数进行分析。
\item 第五章\ 情感分析系统：本文结合各情感分析模型，实现了基于网页的评论情感分类系统。本章主要介绍系统的流程模块及实现方法。
\item 第六章\ 结束语。总结了整个研究过程中的经验，对系统的现有问题进行了归纳，对将来可以改进的地方做了总结。
\end{itemize}